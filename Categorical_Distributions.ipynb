{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the projected probablities\n",
    "# This is an implementation of Algorithm 1 in the Distributional perpective paper: \n",
    "# arXiv:1707.06887 [cs.LG]\n",
    "def projected_prob(vmin, vmax, N, reward, discount, target_prob):\n",
    "    delta = (vmax - vmin)/(N-1)\n",
    "    z = np.array([ vmin + i*delta for i in range(N)])\n",
    "    Tz = np.clip(reward + discount*z, vmin, vmax)\n",
    "    b = (Tz-vmin)/delta\n",
    "    l = np.floor(b).astype(int)\n",
    "    small_shift = 1e-5\n",
    "    u = np.ceil(b+small_shift).astype(int)\n",
    "    projected_probs = np.zeros(N)\n",
    "    for ii, lu in enumerate(zip(l,u)):\n",
    "        ll, uu = lu\n",
    "        if ll in range(N):\n",
    "            projected_probs[ll]+=target_prob[ii]*(uu-b[ii])\n",
    "        if uu in range(N):\n",
    "            projected_probs[uu]+=target_prob[ii]*(b[ii]-ll)\n",
    "    return projected_probs     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to apply projected_prob to the rows of a batch\n",
    "def projected_prob_batch(vmin, vmax, N, discount, rewards, target_probs):\n",
    "    '''This is a much slower implementation. \n",
    "       Try projected_prob_batch2 instead.\n",
    "       Average time taken by this function on a batch of 128 with N = 51: 0.112sec\n",
    "       Average time taken by projected_prob_batch2 on the same computations: 0.0012sec'''\n",
    "    rw_prb = np.concatenate((rewards, target_probs), axis = 1)\n",
    "    fn = lambda x: projected_prob(vmin, vmax, N, x[0], discount, x[1:])\n",
    "    return np.apply_along_axis(fn, 1, rw_prb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_prob_batch2(vmin, vmax, N, discount, rewards, target_probs):\n",
    "    '''This is much faster implementation of projected_prob_batch\n",
    "       Average time taken by this function on a batch of 128 with N = 51: 0.0012sec\n",
    "       Average time taken by projected_prob_batch on the same computations: 0.112sec'''\n",
    "    delta = (vmax - vmin)/(N-1)\n",
    "    z = np.array([ vmin + i*delta for i in range(N)])\n",
    "    # z = np.linspace(vmin, vmax, N)\n",
    "    # I experimented with np.linspace to generate z but it seems to be much slower \n",
    "    Tz = np.clip(rewards + discount*z, vmin, vmax)\n",
    "    b = (Tz-vmin)/delta\n",
    "    l = np.floor(b).astype(int)\n",
    "    small_shift = 1e-10\n",
    "    u = np.ceil(b+small_shift).astype(int)\n",
    "    batch_size = target_probs.shape[0]\n",
    "    # since 'u' can contain a value N+1\n",
    "    # we will therefore first create a zero matrix of shape (batch_size, N+1)\n",
    "    # after appropriately updating it we will simply ignore its (N+1)th column \n",
    "    projected_probs = np.zeros((batch_size, N+1))\n",
    "    for idx in range(N):\n",
    "        ll, uu = l[:,idx], u[:, idx]\n",
    "        projected_probs[np.arange(batch_size), ll]+=target_probs[:, idx]*(uu-b[:,idx])\n",
    "        projected_probs[np.arange(batch_size), uu]+=target_probs[:, idx]*(b[:, idx]-ll)\n",
    "    return projected_probs[:, :N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_computation_time(batch_size = 128, vmin = -10, vmax = 10, N = 51, discount = 1):\n",
    "    # average the timing over 100 iterations\n",
    "    time1 = []\n",
    "    time2 = []\n",
    "    for itr in range(100):\n",
    "        rand = np.random.normal(size = (batch_size, N))\n",
    "        exp =  np.exp(rand) \n",
    "        smi =   1/np.sum(exp, axis = 1)\n",
    "        diag = np.zeros((batch_size,batch_size))\n",
    "        diag[np.arange(batch_size), np.arange(batch_size)] = smi\n",
    "        probs = np.matmul(diag, exp)\n",
    "        if (np.abs(np.sum(probs, axis = 1)-1.0)>1e-10).any():\n",
    "            print('problem in softmax function')\n",
    "            return\n",
    "        \n",
    "        start1 = time.time()\n",
    "        proj_probs1 = projected_prob_batch(vmin, vmax, N, discount, \n",
    "                                           rewards = np.ones((batch_size,1)), \n",
    "                                           target_probs = probs )\n",
    "        end1 = time.time()\n",
    "        time1.append(end1-start1)\n",
    "        if (np.abs(np.sum(proj_probs1, axis = 1)-1.0)>1e-10).any():\n",
    "            print('problem in projected_prob_batch')\n",
    "            return\n",
    "        \n",
    "        start2 = time.time()\n",
    "        proj_probs2 = projected_prob_batch2(vmin, vmax, N, rewards = np.ones((batch_size,1)), \n",
    "                                            discount = discount,  target_probs = probs )\n",
    "        end2 = time.time()\n",
    "        time2.append(end2-start2)\n",
    "        if (np.abs(np.sum(proj_probs2, axis = 1)-1.0)>1e-10).any():\n",
    "            print('problem in projected_prob_batch2')\n",
    "            return\n",
    "        if(np.abs(proj_probs1-proj_probs2)>1e-10).any():\n",
    "            print('results of the two projections do not match ')\n",
    "            return\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(time1, label = 'projected_prob_batch')\n",
    "    plt.plot(time2, label= 'projected_prob_batch2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('average time taken by projected_prob_batch: {}'.format(np.average(time1)))\n",
    "    print('average time taken by projected_prob_batch2: {}'.format(np.average(time2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as projected_prob_batch2 but directly as torch tensors\n",
    "def projected_prob_batch2_torch(vmin, vmax, N, discount, rewards, target_probs, batchsize):\n",
    "    '''Same as projected_prob_batch2 but directly as torch tensors\n",
    "        rewards and target_probs are assumed to be torch tensors'''\n",
    "    delta = (vmax - vmin)/(N-1)\n",
    "    z = torch.linspace(vmin, vmax, N).to(device) \n",
    "    Tz = torch.clamp(rewards + discount*z, vmin, vmax)\n",
    "    b = (Tz-vmin)/delta\n",
    "    l = torch.floor(b).type(torch.long)\n",
    "    small_shift = 1e-5 # shifts smaller than this will not work for float32 tensors\n",
    "    u = torch.ceil(b+small_shift).type(torch.long)\n",
    "    # since 'u' can contain a value N+1\n",
    "    # we will therefore first create a zero matrix of shape (batch_size, N+1)\n",
    "    # after appropriately updating it we will simply ignore its (N+1)th column \n",
    "    projected_probs = torch.zeros((batchsize, N+1)).to(device)\n",
    "    for idx in range(N):\n",
    "        ll, uu = l[:,idx], u[:, idx]\n",
    "        projected_probs[torch.arange(batchsize), ll]+=target_probs[:, idx]*(uu-b[:,idx])\n",
    "        projected_probs[torch.arange(batchsize), uu]+=target_probs[:, idx]*(b[:, idx]-ll)\n",
    "    return projected_probs[:, :N]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drlnd]",
   "language": "python",
   "name": "conda-env-drlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
