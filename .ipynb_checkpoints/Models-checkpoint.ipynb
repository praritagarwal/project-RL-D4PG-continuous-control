{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class actor(nn.Module):\n",
    "    def __init__(self, n_states = 33, n_actions = 4, n_hidden = 50, seed = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        self.l1 = nn.Linear(in_features = self.n_states, out_features = self.n_hidden)\n",
    "        self.l2 = nn.Linear(in_features = self.n_hidden, out_features = self.n_hidden//2)\n",
    "        self.l3 = nn.Linear(in_features = self.n_hidden//2, out_features = self.n_hidden//4)\n",
    "        self.l4 = nn.Linear(in_features = self.n_hidden//4, out_features = self.n_actions)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.selu(self.l1(state))\n",
    "        x = F.selu(self.l2(x))\n",
    "        x = F.selu(self.l3(x))\n",
    "        x = torch.tanh(self.l4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class critic(nn.Module):\n",
    "    def __init__(self, n_states = 33, n_actions= 4, n_atoms = 51, n_hidden = 300, seed = 0, \n",
    "                 output = 'logprob'):\n",
    "        # output: whether output should be softmax or log_softmax\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        if output == 'logprob':\n",
    "            self.act = F.log_softmax\n",
    "        elif output == 'prob':\n",
    "            self.act = F.softmax\n",
    "        else:\n",
    "            print('Wrong value for parameter: output. Please choose from either prob or logprob')\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        self.l1 = nn.Linear(in_features = self.n_states + self.n_actions, out_features = self.n_hidden)\n",
    "        self.l2 = nn.Linear(in_features = self.n_hidden, out_features = (2*self.n_hidden)//3)\n",
    "        self.l3 = nn.Linear(in_features = (2*self.n_hidden)//3, out_features = self.n_hidden//3)\n",
    "        self.l4 = nn.Linear(in_features = self.n_hidden//3, out_features = n_atoms)\n",
    "        \n",
    "    def forward(self, states, actions):\n",
    "        critic_input = torch.cat((states, actions), dim = 1)\n",
    "        x = F.selu(self.l1(critic_input))\n",
    "        x = F.selu(self.l2(x))\n",
    "        x = F.selu(self.l3(x))\n",
    "        x = self.act(self.l4(x), dim = 1) # outputs the log_prob for \n",
    "                                               # each 'atom' of the categorical distribution\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drlnd]",
   "language": "python",
   "name": "conda-env-drlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
